var store = [{
        "title": "minimal mistakes í…Œë§ˆì—ì„œ sidebar ë§Œë“¤ê¸°",
        "excerpt":"minimal mistakes ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì“´ ê¸€ ì…ë‹ˆë‹¤.   ë¨¼ì € í…ŒìŠ¤íŠ¸ ìš©ìœ¼ë¡œ ë¬¸ì„œì— ë‚˜ì™€ìˆëŠ” ê·¸ëŒ€ë¡œ ë³µì‚¬ì—ì„œ ì´ í¬ìŠ¤íŠ¸ì˜ YAML Front Matterì— ë¶™ì—¬ë„£ê¸° í•´ì¤¬ë‹¤.   (ì‚¬ì§„) ì˜¤, ì‚¬ì´ë“œë¡œ ë‚˜ì™”ë‹¤.   í•˜ì§€ë§Œ ì € ë¬¸ì„œì²˜ëŸ¼ ì‚¬ì´ë“œ ë°”ë¥¼ ë§Œë“¤ê³  ì‹¶ê¸° ë•Œë¬¸ì— custom-sidebar-contentë¥¼ ë”°ë¼ í•´ë³´ê² ë‹¤.   êµ¬ì„±í•˜ê³  ì‹¶ì€ ì‚¬ì´ë“œ ë°” ì¹´í…Œê³ ë¦¬ëŠ”      Machine Learning   Algorithm   Server   iOS   Python ì´ ì •ë„ë¡œ í•´ë†“ê² ë‹¤.   notionì— ì •ë¦¬í–ˆë˜ ë…¸íŠ¸ë“¤ì„ ì´ ë¸”ë¡œê·¸ì— í•˜ë‚˜ì”© ê°€ì ¸ì˜¬ ê±°ë¼ ë¯¸ë¦¬ childrenì— ì¨ì£¼ê² ë‹¤.   docs:   - title: Machine Learning     children:       - title: \"ë‚´ ë°ì´í„°ë¡œ CNN ëŒë ¤ë³´ê¸°\"         url: /_pages/cnn/       - title: \"ë‚´ ë°ì´í„°ë¡œ ResNet ëŒë ¤ë³´ê¸°\"         url: /_pages/resnet/       - title: \"AWS Sagemakerì—ì„œ ResNet ëŒë ¤ë³´ê¸°\"         url: /_pages/sagemaker/    - title: Algorithm     children:       - title: \"Configuration\"         url: /docs/configuration/    - title: Server     children:       - title: \"Configuration\"         url: /docs/configuration/    - title: iOS     children:       - title: \"[Swift] ë„¤ë¹„ê²Œì´ì…˜ ë°”, í™”ë©´ ì´ë™\"         url: /_pages/swift1/       - title: \"[Swift] ì›¹ë·°(WKWebView), ì˜µì…”ë„ ë°”ì¸ë”©(optional binding)\"         url: /_pages/swift2/    - title: Python     children:       - title: \"Configuration\"         url: /docs/configuration/   ì´ë ‡ê²Œ í¬ìŠ¤íŠ¸ë¥¼ ì „ë¶€ ë‹¤ ì‚¬ì´ë“œ ë°”ì— í‘œì‹œí•˜ë©´ ë‚˜ì¤‘ì— ì§€ì €ë¶„í•´ì§€ê² ì§€ë§Œ ì§€ê¸ˆì€ ì‚¬ì´ë“œ ë°” ë§Œë“œëŠ” ê²Œ ëª©í‘œë‹ˆê¹Œ ê·¸ëƒ¥ í•´ì£¼ê² ë‹¤.   _config.yml íŒŒì¼ì˜ defaults ë¶€ë¶„ì— í‘œì‹œí•´ì¤€ë‹¤.   defaults:   # _docs   - scope:       path: \"\"       type: docs     values:       sidebar:         nav: \"docs\"   (ì‚¬ì§„)   ì•ˆ ë‚˜ì˜¤ë„¤,,? ì™œì§€,,   í¬ìŠ¤íŠ¸ì˜ YAML Front Matterì— ë‹¤ìŒê³¼ ê°™ì´ ë„£ì–´ì£¼ë©´ ë‚˜ì˜¤ëŠ”ë°, ì´ í¬ìŠ¤íŠ¸ì—ë§Œ í•´ë‹¹í•˜ëŠ”ê±°ë¼,, ğŸ¤¦â€â™€ï¸   sidebar:   nav: \"docs\"   ì¼ë‹¨ ì”ë‹¤..  ","categories": ["blogging"],
        "tags": [],
        "url": "http://localhost:4000/minimal-mistakes-sidebar",
        "teaser": null
      },{
        "title": "Cnn Own Data",
        "excerpt":"ë‚´ ë°ì´í„°ë¡œ CNN ëŒë ¤ë³´ê¸°   ìº¡ìŠ¤í†¤ í”„ë¡œì íŠ¸   ë°ì´í„° ì¤€ë¹„í•˜ê¸°     ìš°ë¦¬ëŠ” 6ê°œ í´ë˜ìŠ¤ë¥¼ ê°€ì§€ê³  ìˆê³  ì–´ì©Œêµ¬ ê·¼ë° ì§€ê¸ˆì€ 3ê°œ í´ë˜ìŠ¤ì— ëŒ€í•œ ë°ì´í„°ë§Œ ìã…†ì–´ì„œ ì¼ë‹¨ ì„¸ê°œë¡œë§Œ í•´ë³´ê² ìŒ.   AWS Sagemakerë¥¼ ì´ìš©í•  ê³„íšì¸ë°, ê·¸ëŸ¬ë ¤ë©´ ë°ì´í„°ì…‹ì„ pkl íŒŒì¼ë¡œ ë§Œë“¤ì–´ì•¼ í•œë‹¤.   ì§„ì§œ ì—¬ê¸°ì €ê¸° ì‚½ì§ˆí•˜ë‹¤ê°€ ì´ ê¹ƒí—™ì„ ë°œê²¬í•˜ê³  ë”°ë¼í•´ë´¤ë‹¤!   train, valid, test í´ë”ë¥¼ ë§Œë“¤ê³  ë°ì´í„°ë¥¼ 7:2:1ì˜ ë¹„ìœ¨ë¡œ ë„£ì–´ì£¼ì—ˆë‹¤.   1. labelì´ ë“¤ì–´ê°„ csv íŒŒì¼ ë§Œë“¤ì–´ì£¼ê¸°   csv íŒŒì¼ì„ ë§Œë“¤ì–´ì£¼ëŠ” ì½”ë“œë¥¼ ì‘ì„±í–ˆë‹¤.   import os import natsort import csv import re  file_path = 'test/' file_lists = os.listdir(file_path) file_lists = natsort.natsorted(file_lists)  f = open('train.csv', 'w', encoding='utf-8') #valid.csv, test.csv wr = csv.writer(f) wr.writerow([\"Img_name\", \"Class\"]) for file_name in file_lists:     print(file_name)     wr.writerow([file_name, re.sub('-\\d*[.]\\w{3}', '', file_name)]) f.close()   ì´ë ‡ê²Œ ì‘ì„±í•´ì„œ ì‹¤í–‰í•´ì£¼ë©´ ê°„ë‹¨í•˜ê²Œ csv íŒŒì¼ ë§Œë“¤ê¸° ì„±ê³µ ã€°ï¸   train.csvë¥¼ ì—´ë©´ ì´ë ‡ê²Œ ìƒê²¼ë‹¤!      2. ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •í•˜ê¸°      ì›ë˜ ì´ë¯¸ì§€ í¬ê¸°ëŠ” 310x770 ì‚¬ì´ì¦ˆì˜€ìŒ   ì´ê±¸ 32x32ë¡œ ë°”ê¿”ë³´ê² ë‹¤!   â—ï¸ì–´ë–¤ í¬ê¸°ê°€ ì ë‹¹í•œì§€ ëª°ë¼ì„œ ì¼ë‹¨ 32, 32ë¡œ í•¨â—ï¸   (ë°”ê¿”ë³´ë‹ˆ ì´ë¯¸ì§€ê°€ ë„ˆë¬´ ê¹¨ì§€ë‚˜ ì‹¶ì–´ì„œ í•™ìŠµ ì§„í–‰í•˜ë©´ì„œ ì¡°ì ˆí•  ì˜ˆì •)         ê¹ƒí—™ ì½”ë“œëŠ” ì´ë¯¸ì§€ í¬ê¸° ë³€ê²½ì„ Shell ìŠ¤í¬ë¦½íŠ¸ë¡œ í–ˆë˜ë°, ë‚œ íŒŒì´ì¬ ì½”ë“œë¡œ ë§Œë“¤ì—ˆìŒ   from PIL import Image import os import natsort import csv import re  img_size = (32, 32)  def resize_img(img_path):     img_lists = os.listdir(img_path)     img_lists = natsort.natsorted(img_lists)     for img_name in img_lists:         print(f'{img_path}{img_name}')         image = Image.open(f'{img_path}{img_name}')         image = image.resize(img_size)         image.save(f'{img_path}{img_name}')  resize_img('train/') resize_img('valid/') resize_img('test/')      ì´ë ‡ê²Œ í•´ì„œ 32, 32 ì‚¬ì´ì¦ˆì˜ ì´ë¯¸ì§€ë¡œ ë³€ê²½!   ì½©ì•Œë§Œ í•´ì¡Œë‹¤.      ì´ì œ ì´ ë°ì´í„°ì…‹ìœ¼ë¡œ í”¼í´ë§ì„ ì§„í–‰í•´ë³´ê² ìŒ!   3. pkl íŒŒì¼ë¡œ ë§Œë“¤ê¸°   ê¹ƒí—™ ì½”ë“œì™€ ë‹¤ë¥¸ ì       ì›ë˜ëŠ” grayscaleë¡œ ë³€í™˜í–ˆëŠ”ë°, ë‚œ rgb ê·¸ëŒ€ë¡œ ê°€ì§€ê³  ê°€ê² ë‹¤~!   python2ë¡œ ì‘ì„±í–ˆëŠ”ì§€ cPickleì„ ì‚¬ìš©í–ˆëŠ”ë°, ë‚œ python3ì´ë‹ˆê¹Œ _pickleì„ ì‚¬ìš©í•¨   from PIL import Image from numpy import genfromtxt import gzip import _pickle from glob import glob import numpy as np import pandas as pd  def dir_to_dataset(glob_files, loc_train_labels=\"\"):     print(\"Gonna process:\\n\\t %s\"%glob_files)     dataset = []     for file_count, file_name in enumerate( sorted(glob(glob_files),key=len) ):         img = Image.open(file_name)         pixels = [f[0] for f in list(img.getdata())]         dataset.append(pixels)         if file_count % 1000 == 0:             print(\"\\t %s files processed\"%file_count)     # outfile = glob_files+\"out\"     # np.save(outfile, dataset)     if len(loc_train_labels) &gt; 0:         df = pd.read_csv(loc_train_labels, names = [\"class\"])         return np.array(dataset), np.array(df[\"class\"])     else:         return np.array(dataset)  Data1, y1 = dir_to_dataset(\"train/*.png\",\"train.csv\") Data2, y2 = dir_to_dataset(\"valid/*.png\",\"valid.csv\") Data3, y3 = dir_to_dataset(\"test/*.png\",\"test.csv\")  # Data and labels are read train_num = 2758 valid_num = 844 test_num = 420  train_set_x = Data1[:train_num] train_set_y = y1[1:train_num+1] val_set_x = Data2[:valid_num] val_set_y = y2[1:valid_num+1] test_set_x = Data3[:test_num] test_set_y = y3[1:test_num+1]  train_set = train_set_x, train_set_y val_set = val_set_x, val_set_y test_set = test_set_x, test_set_y  dataset = [train_set, val_set, test_set]  f = gzip.open('soundee.pkl.gz','wb') _pickle.dump(dataset, f, protocol=2) f.close()   ë°ì´í„° ë¡œë“œí•˜ê¸°     https://www.analyticsvidhya.com/blog/2020/02/learn-image-classification-cnn-convolutional-neural-networks-3-datasets/   ì´ì œ ë³¸ê²©ì ìœ¼ë¡œ í•™ìŠµì„ ì‹œì‘í•´ë³´ì!           ë¨¼ì € ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³        %%time import _pickle, gzip, urllib.request, json import numpy as np  with gzip.open('soundee.pkl.gz', 'rb') as f:     train_set, valid_set, test_set = _pickle.load(f, encoding='latin1')                ì´ë¯¸ì§€ì™€ ë ˆì´ë¸”ë¡œ ê°ê° ë‚˜ëˆ ì£¼ê³        (train_images, train_labels), (valid_images, valid_labels), (test_images, test_labels) = train_set, valid_set, test_set                input ë²¡í„°       train_images = train_images.reshape(train_images.shape[0], 32, 32, 3) valid_images = valid_images.reshape(valid_images.shape[0], 32, 32, 3) test_images = test_images.reshape(test_images.shape[0], 32, 32, 3)  train_images = train_images.astype('float32') valid_images = valid_images.astype('float32') test_images = test_images.astype('float32')                  â€¦.       ê·¸ë˜ ì›¬ì¼ë¡œ ì˜ ë‚˜ê°€ë‚˜ í–ˆë‹¤^~^       CIFAR-10 ë°ì´í„°ì…‹ì„ ë°›ì•„ì„œ ë°ì´í„° shapeì„ ì¶œë ¥í•´ë´„      ì´ê±´ ë‚´ ë°ì´í„°      1024,,? ë„Œ ì™œ,, 32*32ê°€ ë˜ì–´ìˆë‹ˆ,,?   ê·¸ë¦¬ê³  rgb ì±„ë„ì€ ë˜ ì–´ë”° íŒ”ì•„ë¨¹ì—ˆì–´   ì–´í‘   pkl íŒŒì¼ ì €ì¥ì´ ì˜ëª»ëœ ê²ƒ ê°™ì•„ì„œ,,^^ ë‹¤ì‹œ ëœ¯ì–´ë³´ë‹¤ê°€   pixels = [f[0] for f in list(img.getdata())]   ì—¬ê¸°ê°€ ë¬¸ì œì¸ ê²ƒ ê°™ì€ ì‚˜ì´ ì™”ë‹¤.   ê²€ìƒ‰í•˜ë‹¤ ìŠ¤íƒì˜¤ë²„í”Œë¡œìš°ì—ì„œ import imageio im = imageio.imread('sogreche.jpg')   ì´ ë¶€ë¶„ì„ ë³´ê³  ì†Œë¦„ ì«™ ë‹ì•„ì„œ ëª¨ë“ˆ ë‹¤ìš´ë°›ê³  ë¬¸ì„œ ì°¾ì•„ì„œ í•´ë´¤ë‹¤.      ëˆˆë¬¼ë‚˜. ëë‹¤.   ë‹¤ì‹œ ë°ì´í„° ë¡œë“œ í•´ë³´ê³       ë–´ë‹¤..      ì´ë¯¸ì§€ë„ ì˜ ëœ¬ë‹¤. ë¯¸ì³¤ë‹¤   ë¯¸ ì³¤ ì–´   ì´ì œ ë‹¤ì‹œ í•´ë³´ì,,,,           input vector       train_images = train_images.reshape(train_images.shape[0], 32, 32, 3) valid_images = valid_images.reshape(valid_images.shape[0], 32, 32, 3) test_images = test_images.reshape(test_images.shape[0], 32, 32, 3)  train_images = train_images.astype('float32') valid_images = valid_images.astype('float32') test_images = test_images.astype('float32')           ì•„ì•„ì•… ëœë‹¤ì•„ì•…       ì•„ ê¸°ë¹¨ë ¤,, ë°¥ ë¨¹ê³  ì˜¬ë˜ ë¨¹ê³  ì˜´!            ì´ë¯¸ì§€ í”½ì…€ ê°’ ì •ê·œí™” í•´ì£¼ê¸°       # normalizing the data to help with the training train_images /= 255 valid_images /= 255 test_images /= 255                one-hot ì¸ì½”ë”© í•´ì£¼ê¸°       # one-hot encoding using keras' numpy-related utilities n_classes = 3 print(\"Shape before one-hot encoding: \", train_labels.shape) train_labels = np_utils.to_categorical(train_labels, n_classes) valid_labels = np_utils.to_categorical(valid_labels, n_classes) test_labels = np_utils.to_categorical(test_labels, n_classes) print(\"Shape after one-hot encoding: \", train_labels.shape)              ì˜¤ë¥˜ê°€ ë°œìƒí–ˆë‹¤,,   ì½ì–´ë³´ë‹ˆ labelì´ ìˆ«ìì—¬ì•¼ í•˜ë‚˜ë³´ë‹¤   ê·¸ë˜ì„œ ì´ ë¸”ë¡œê·¸ ê¸€ì„ ë³´ê³  intë¡œ ë°”ê¿”ì¤¬ë‹¤!   from sklearn.preprocessing import LabelEncoder  def encoding_to_int(labels):     e = LabelEncoder()     e.fit(labels)     return e.transform(labels)  n_classes = 3 print(\"Shape before one-hot encoding: \", train_labels.shape) train_labels = np_utils.to_categorical(encoding_to_int(train_labels), n_classes) valid_labels = np_utils.to_categorical(encoding_to_int(valid_labels), n_classes) test_labels = np_utils.to_categorical(encoding_to_int(test_labels), n_classes) print(\"Shape after one-hot encoding: \", train_labels.shape)      ìŒ. ì˜ ëŒì•„ê°€ëŠ”êµ°! ì´ì œ ë‹¤ìŒ ã€°ï¸   ëª¨ë¸ ë¹Œë“œ &amp; í•™ìŠµí•˜ê¸°     ìš°ë¦¬ì˜ ìµœì¢… ëª©í‘œëŠ” resnetìœ¼ë¡œ ëŒë¦¬ëŠ” ê±´ë°, ì¼ë‹¨ í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ì´ ë¸”ë¡œê·¸ì—ì„œ sequential APIë¡œ ë§Œë“  cnn ëª¨ë¸ ê·¸ëŒ€ë¡œ ì¨ì£¼ê² ìŒ!    # building a linear stack of layers with the sequential model model = Sequential()  # convolutional layer model.add(Conv2D(50, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu', input_shape=(32, 32, 3)))  # convolutional layer model.add(Conv2D(75, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')) model.add(MaxPool2D(pool_size=(2,2))) model.add(Dropout(0.25))  model.add(Conv2D(125, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')) model.add(MaxPool2D(pool_size=(2,2))) model.add(Dropout(0.25))  # flatten output of conv model.add(Flatten())  # hidden layer model.add(Dense(500, activation='relu')) model.add(Dropout(0.4)) model.add(Dense(250, activation='relu')) model.add(Dropout(0.3)) # output layer model.add(Dense(3, activation='softmax'))  # compiling the sequential model model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')   í…ŒìŠ¤íŠ¸ë‹ˆê¹Œ ê°„ë‹¨ì“°í•˜ê²Œ 10epochë§Œ ëŒë ¤ë³´ê¸° ~,~   # training the model for 10 epochs model.fit(train_images, train_labels, batch_size=64, epochs=10, validation_data=(valid_images, valid_labels))      ìŒ ê²°ê³¼ê°€ ì•„ì£¼ ë³„ë¡œë‹¤. ê´œì°®ì•„   ì •í™•ë„ í‰ê°€í•˜ê¸°     test_setìœ¼ë¡œ ì •í™•ë„ í‰ê°€í•˜ê¸°~!   test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)  print('\\ní…ŒìŠ¤íŠ¸ ì •í™•ë„:', test_acc)      ì™€ìš° í…ŒìŠ¤íŠ¸ ì •í™•ë„ ì§„ì§œ ë‚œë¦¬ë‚¬ë‹¤. ê´œì°®ë‹¤   ì˜ˆì¸¡ë§Œë“¤ê¸°     prediction = model.predict(test_images) np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})   ê°„ë‹¨í•˜ê²Œë§Œ ë³¼ ê±°ë¼ ì˜ˆì¸¡ ë ˆì´ë¸”ì„ ì•„ë¬´ë ‡ê²Œë‚˜ ì¶œë ¥í•´ë³´ê² ë‹¤!   cnt = 0 for i in prediction:     pre_ans = i.argmax()     pre_ans_str = ''     if pre_ans == 0: pre_ans_str = \"drop\"     elif pre_ans == 1: pre_ans_str = \"motor\"     elif pre_ans == 2: pre_ans_str = \"water\"       if i[0] &gt;= 0.4 : print(f\"{test_labels[cnt]} ì´ë¯¸ì§€ëŠ” {pre_ans_str}ë¡œ ì¶”ì •ë©ë‹ˆë‹¤.\")     if i[1] &gt;= 0.4: print(f\"{test_labels[cnt]} ì´ë¯¸ì§€ëŠ” {pre_ans_str}ë¡œ ì¶”ì •ë©ë‹ˆë‹¤.\")     if i[2] &gt;= 0.4: print(f\"{test_labels[cnt]} ì´ë¯¸ì§€ëŠ” {pre_ans_str}ë¡œ ì¶”ì •ë©ë‹ˆë‹¤.\")     if i[0] &lt; 0.4 and i[1] &lt; 0.4 and i[2] &lt; 0.4 : print(f\"{test_labels[i]} ì´ë¯¸ì§€ë¥¼ ì¶”ì •í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")     print()     cnt += 1      ì¢‹ì•„ì“°. ê¸°ë³¸ cnn ëŒì•„ê°€ëŠ”ê±° í™•ì¸í–ˆìœ¼ë‹ˆ ì´ì œ      resnetìœ¼ë¡œ í•™ìŠµí•˜ê³    ìµœì  ëª¨ë¸ ì €ì¥í•˜ê³    ëª¨ë¸ ë¶ˆëŸ¬ ì™€ì„œ ì˜ˆì¸¡   ê¸°ê³„í•™ìŠµ ëª¨í˜• ë°°í¬   ì´ë ‡ê²Œ í•´ë³´ê² ë‹¤.   ìš°ë¦¬ëŠ” ì‹¤ì‹œê°„ìœ¼ë¡œ ë“¤ì–´ì˜¤ëŠ” ì†Œë¦¬ ë°ì´í„°ë¥¼ ì…ë ¥ìœ¼ë¡œ í•´ì„œ ì˜ˆì¸¡ ëª¨ë¸ì— ë„£ê³  ì˜ˆì¸¡ê°’ ë°›ê³ , ê·¸ê±¸ ì• í”Œë¦¬ì¼€ì´ì…˜ì— ë„˜ê²¨ì¤˜ì•¼ í•œë‹¤.   ì´ê±¸ sagemakerì—ì„œ í•´ì•¼ í•˜ëŠ”ë°,,, ë¯¸ì¹œ ì•ˆëœë‹¤. ìš¸ê³ ì‹¶ë‹¤. ê·¸ë˜ë„ í•´ì•¼í•˜ë‹ˆ í•´ë³´ê² ë‹¤..^^   ì´ë²ˆ í¬ìŠ¤íŒ… ë ~,~   ë‹¤ìŒ í¬ìŠ¤íŒ… ğŸ‘‰ ë‚´ ë°ì´í„°ë¡œ ResNet ëŒë ¤ë³´ê¸°  ","categories": ["machine_learning"],
        "tags": ["AI","CNN","ML"],
        "url": "http://localhost:4000/cnn-own-data",
        "teaser": null
      }]
