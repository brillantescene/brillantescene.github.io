---
title:
categories: machine_learning
last_modified_at: 2020-09-07 18:29:51
tags: [AI, CNN, ML]
toc: true
toc_sticky: true
sidebar:
  nav: "docs"
---

# ë‚´ ë°ì´í„°ë¡œ CNN ëŒë ¤ë³´ê¸°

ìº¡ìŠ¤í†¤ í”„ë¡œì íŠ¸

# ë°ì´í„° ì¤€ë¹„í•˜ê¸°

---

ìš°ë¦¬ëŠ” 6ê°œ í´ë˜ìŠ¤ë¥¼ ê°€ì§€ê³  ìˆê³  ì–´ì©Œêµ¬ ê·¼ë° ì§€ê¸ˆì€ 3ê°œ í´ë˜ìŠ¤ì— ëŒ€í•œ ë°ì´í„°ë§Œ ìã…†ì–´ì„œ ì¼ë‹¨ ì„¸ê°œë¡œë§Œ í•´ë³´ê² ìŒ.

AWS Sagemakerë¥¼ ì´ìš©í•  ê³„íšì¸ë°, ê·¸ëŸ¬ë ¤ë©´ ë°ì´í„°ì…‹ì„ pkl íŒŒì¼ë¡œ ë§Œë“¤ì–´ì•¼ í•œë‹¤.

ì§„ì§œ ì—¬ê¸°ì €ê¸° ì‚½ì§ˆí•˜ë‹¤ê°€ ì´ [ê¹ƒí—™](https://github.com/tikroute/mnist.pkl.gz-dataset-creator)ì„ ë°œê²¬í•˜ê³  ë”°ë¼í•´ë´¤ë‹¤!

train, valid, test í´ë”ë¥¼ ë§Œë“¤ê³  ë°ì´í„°ë¥¼ 7:2:1ì˜ ë¹„ìœ¨ë¡œ ë„£ì–´ì£¼ì—ˆë‹¤.

## 1. labelì´ ë“¤ì–´ê°„ csv íŒŒì¼ ë§Œë“¤ì–´ì£¼ê¸°

csv íŒŒì¼ì„ ë§Œë“¤ì–´ì£¼ëŠ” ì½”ë“œë¥¼ ì‘ì„±í–ˆë‹¤.

```python
import os
import natsort
import csv
import re

file_path = 'test/'
file_lists = os.listdir(file_path)
file_lists = natsort.natsorted(file_lists)

f = open('train.csv', 'w', encoding='utf-8') #valid.csv, test.csv
wr = csv.writer(f)
wr.writerow(["Img_name", "Class"])
for file_name in file_lists:
    print(file_name)
    wr.writerow([file_name, re.sub('-\d*[.]\w{3}', '', file_name)])
f.close()
```

ì´ë ‡ê²Œ ì‘ì„±í•´ì„œ ì‹¤í–‰í•´ì£¼ë©´ ê°„ë‹¨í•˜ê²Œ csv íŒŒì¼ ë§Œë“¤ê¸° ì„±ê³µ ã€°ï¸

`train.csv`ë¥¼ ì—´ë©´ ì´ë ‡ê²Œ ìƒê²¼ë‹¤!

![2020-08-284.03.46.png](/assets/images/posts/2020-09-07/2020-08-284.03.46.png)

## 2. ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •í•˜ê¸°

- ì›ë˜ ì´ë¯¸ì§€ í¬ê¸°ëŠ” 310x770 ì‚¬ì´ì¦ˆì˜€ìŒ
- ì´ê±¸ 32x32ë¡œ ë°”ê¿”ë³´ê² ë‹¤!

**â—ï¸ì–´ë–¤ í¬ê¸°ê°€ ì ë‹¹í•œì§€ ëª°ë¼ì„œ ì¼ë‹¨ 32, 32ë¡œ í•¨â—ï¸**

(ë°”ê¿”ë³´ë‹ˆ ì´ë¯¸ì§€ê°€ ë„ˆë¬´ ê¹¨ì§€ë‚˜ ì‹¶ì–´ì„œ í•™ìŠµ ì§„í–‰í•˜ë©´ì„œ ì¡°ì ˆí•  ì˜ˆì •)

![1-2.png](/assets/images/posts/2020-09-07/1-2.png)

- ê¹ƒí—™ ì½”ë“œëŠ” ì´ë¯¸ì§€ í¬ê¸° ë³€ê²½ì„ Shell ìŠ¤í¬ë¦½íŠ¸ë¡œ í–ˆë˜ë°, ë‚œ íŒŒì´ì¬ ì½”ë“œë¡œ ë§Œë“¤ì—ˆìŒ

```python
from PIL import Image
import os
import natsort
import csv
import re

img_size = (32, 32)

def resize_img(img_path):
    img_lists = os.listdir(img_path)
    img_lists = natsort.natsorted(img_lists)
    for img_name in img_lists:
        print(f'{img_path}{img_name}')
        image = Image.open(f'{img_path}{img_name}')
        image = image.resize(img_size)
        image.save(f'{img_path}{img_name}')

resize_img('train/')
resize_img('valid/')
resize_img('test/')
```

- ì´ë ‡ê²Œ í•´ì„œ 32, 32 ì‚¬ì´ì¦ˆì˜ ì´ë¯¸ì§€ë¡œ ë³€ê²½!
- ì½©ì•Œë§Œ í•´ì¡Œë‹¤.

![drop-4.png](/assets/images/posts/2020-09-07/drop-4.png)

ì´ì œ ì´ ë°ì´í„°ì…‹ìœ¼ë¡œ í”¼í´ë§ì„ ì§„í–‰í•´ë³´ê² ìŒ!

## 3. pkl íŒŒì¼ë¡œ ë§Œë“¤ê¸°

ê¹ƒí—™ ì½”ë“œì™€ ë‹¤ë¥¸ ì 

- ì›ë˜ëŠ” grayscaleë¡œ ë³€í™˜í–ˆëŠ”ë°, ë‚œ rgb ê·¸ëŒ€ë¡œ ê°€ì§€ê³  ê°€ê² ë‹¤~!
- `python2`ë¡œ ì‘ì„±í–ˆëŠ”ì§€ `cPickle`ì„ ì‚¬ìš©í–ˆëŠ”ë°, ë‚œ `python3`ì´ë‹ˆê¹Œ `_pickle`ì„ ì‚¬ìš©í•¨

```python
from PIL import Image
from numpy import genfromtxt
import gzip
import _pickle
from glob import glob
import numpy as np
import pandas as pd

def dir_to_dataset(glob_files, loc_train_labels=""):
    print("Gonna process:\n\t %s"%glob_files)
    dataset = []
    for file_count, file_name in enumerate( sorted(glob(glob_files),key=len) ):
        img = Image.open(file_name)
        pixels = [f[0] for f in list(img.getdata())]
        dataset.append(pixels)
        if file_count % 1000 == 0:
            print("\t %s files processed"%file_count)
    # outfile = glob_files+"out"
    # np.save(outfile, dataset)
    if len(loc_train_labels) > 0:
        df = pd.read_csv(loc_train_labels, names = ["class"])
        return np.array(dataset), np.array(df["class"])
    else:
        return np.array(dataset)

Data1, y1 = dir_to_dataset("train/*.png","train.csv")
Data2, y2 = dir_to_dataset("valid/*.png","valid.csv")
Data3, y3 = dir_to_dataset("test/*.png","test.csv")

# Data and labels are read
train_num = 2758
valid_num = 844
test_num = 420

train_set_x = Data1[:train_num]
train_set_y = y1[1:train_num+1]
val_set_x = Data2[:valid_num]
val_set_y = y2[1:valid_num+1]
test_set_x = Data3[:test_num]
test_set_y = y3[1:test_num+1]

train_set = train_set_x, train_set_y
val_set = val_set_x, val_set_y
test_set = test_set_x, test_set_y

dataset = [train_set, val_set, test_set]

f = gzip.open('soundee.pkl.gz','wb')
_pickle.dump(dataset, f, protocol=2)
f.close()
```

# ë°ì´í„° ë¡œë“œí•˜ê¸°

---

[https://www.analyticsvidhya.com/blog/2020/02/learn-image-classification-cnn-convolutional-neural-networks-3-datasets/](https://www.analyticsvidhya.com/blog/2020/02/learn-image-classification-cnn-convolutional-neural-networks-3-datasets/)

ì´ì œ ë³¸ê²©ì ìœ¼ë¡œ í•™ìŠµì„ ì‹œì‘í•´ë³´ì!

- ë¨¼ì € ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³ 

  ```python
  %%time
  import _pickle, gzip, urllib.request, json
  import numpy as np

  with gzip.open('soundee.pkl.gz', 'rb') as f:
      train_set, valid_set, test_set = _pickle.load(f, encoding='latin1')
  ```

- ì´ë¯¸ì§€ì™€ ë ˆì´ë¸”ë¡œ ê°ê° ë‚˜ëˆ ì£¼ê³ 

  ```python
  (train_images, train_labels), (valid_images, valid_labels), (test_images, test_labels) = train_set, valid_set, test_set
  ```

- input ë²¡í„°

  ```python
  train_images = train_images.reshape(train_images.shape[0], 32, 32, 3)
  valid_images = valid_images.reshape(valid_images.shape[0], 32, 32, 3)
  test_images = test_images.reshape(test_images.shape[0], 32, 32, 3)

  train_images = train_images.astype('float32')
  valid_images = valid_images.astype('float32')
  test_images = test_images.astype('float32')
  ```

  ![2020-08-286.20.33.png](/assets/images/posts/2020-09-07/2020-08-286.20.33.png)

  ....

  **ê·¸ë˜ ì›¬ì¼ë¡œ ì˜ ë‚˜ê°€ë‚˜ í–ˆë‹¤^~^**

CIFAR-10 ë°ì´í„°ì…‹ì„ ë°›ì•„ì„œ ë°ì´í„° shapeì„ ì¶œë ¥í•´ë´„

![2020-08-286.32.19.png](/assets/images/posts/2020-09-07/2020-08-286.32.19.png)

ì´ê±´ ë‚´ ë°ì´í„°

![2020-08-286.29.18.png](/assets/images/posts/2020-09-07/2020-08-286.29.18.png)

1024,,? ë„Œ ì™œ,, 32\*32ê°€ ë˜ì–´ìˆë‹ˆ,,?

ê·¸ë¦¬ê³  rgb ì±„ë„ì€ ë˜ ì–´ë”° íŒ”ì•„ë¨¹ì—ˆì–´

ì–´í‘

pkl íŒŒì¼ ì €ì¥ì´ ì˜ëª»ëœ ê²ƒ ê°™ì•„ì„œ,,^^ ë‹¤ì‹œ ëœ¯ì–´ë³´ë‹¤ê°€

```python
pixels = [f[0] for f in list(img.getdata())]
```

ì—¬ê¸°ê°€ ë¬¸ì œì¸ ê²ƒ ê°™ì€ ì‚˜ì´ ì™”ë‹¤.

ê²€ìƒ‰í•˜ë‹¤ [ìŠ¤íƒì˜¤ë²„í”Œë¡œìš°](https://stackoverflow.com/questions/1109422/getting-list-of-pixel-values-from-pil)ì—ì„œ `import imageio im = imageio.imread('sogreche.jpg')`

ì´ ë¶€ë¶„ì„ ë³´ê³  ì†Œë¦„ ì«™ ë‹ì•„ì„œ ëª¨ë“ˆ ë‹¤ìš´ë°›ê³  ë¬¸ì„œ ì°¾ì•„ì„œ í•´ë´¤ë‹¤.

![2020-08-302.32.51.png](/assets/images/posts/2020-09-07/2020-08-302.32.51.png)

ëˆˆë¬¼ë‚˜. ëë‹¤.

ë‹¤ì‹œ ë°ì´í„° ë¡œë“œ í•´ë³´ê³ 

![2020-08-302.34.12.png](/assets/images/posts/2020-09-07/2020-08-302.34.12.png)

ë–´ë‹¤..

![2020-08-302.34.56.png](/assets/images/posts/2020-09-07/2020-08-302.34.56.png)

ì´ë¯¸ì§€ë„ ì˜ ëœ¬ë‹¤. ë¯¸ì³¤ë‹¤

ë¯¸ ì³¤ ì–´

ì´ì œ ë‹¤ì‹œ í•´ë³´ì,,,,

- input vector

  ```python
  train_images = train_images.reshape(train_images.shape[0], 32, 32, 3)
  valid_images = valid_images.reshape(valid_images.shape[0], 32, 32, 3)
  test_images = test_images.reshape(test_images.shape[0], 32, 32, 3)

  train_images = train_images.astype('float32')
  valid_images = valid_images.astype('float32')
  test_images = test_images.astype('float32')
  ```

  ì•„ì•„ì•… ëœë‹¤ì•„ì•…

  ~~ì•„ ê¸°ë¹¨ë ¤,, ë°¥ ë¨¹ê³  ì˜¬ë˜~~ ë¨¹ê³  ì˜´!

- ì´ë¯¸ì§€ í”½ì…€ ê°’ ì •ê·œí™” í•´ì£¼ê¸°

  ```python
  # normalizing the data to help with the training
  train_images /= 255
  valid_images /= 255
  test_images /= 255
  ```

- one-hot ì¸ì½”ë”© í•´ì£¼ê¸°

  ```python
  # one-hot encoding using keras' numpy-related utilities
  n_classes = 3
  print("Shape before one-hot encoding: ", train_labels.shape)
  train_labels = np_utils.to_categorical(train_labels, n_classes)
  valid_labels = np_utils.to_categorical(valid_labels, n_classes)
  test_labels = np_utils.to_categorical(test_labels, n_classes)
  print("Shape after one-hot encoding: ", train_labels.shape)
  ```

![2020-08-285.09.17.png](/assets/images/posts/2020-09-07/2020-08-285.09.17.png)

ì˜¤ë¥˜ê°€ ë°œìƒí–ˆë‹¤,,

ì½ì–´ë³´ë‹ˆ labelì´ ìˆ«ìì—¬ì•¼ í•˜ë‚˜ë³´ë‹¤

ê·¸ë˜ì„œ [ì´ ë¸”ë¡œê·¸](https://kwong3.tistory.com/6) ê¸€ì„ ë³´ê³  intë¡œ ë°”ê¿”ì¤¬ë‹¤!

```python
from sklearn.preprocessing import LabelEncoder

def encoding_to_int(labels):
    e = LabelEncoder()
    e.fit(labels)
    return e.transform(labels)

n_classes = 3
print("Shape before one-hot encoding: ", train_labels.shape)
train_labels = np_utils.to_categorical(encoding_to_int(train_labels), n_classes)
valid_labels = np_utils.to_categorical(encoding_to_int(valid_labels), n_classes)
test_labels = np_utils.to_categorical(encoding_to_int(test_labels), n_classes)
print("Shape after one-hot encoding: ", train_labels.shape)
```

![2020-08-286.06.11.png](/assets/images/posts/2020-09-07/2020-08-286.06.11.png)

ìŒ. ì˜ ëŒì•„ê°€ëŠ”êµ°! ì´ì œ ë‹¤ìŒ ã€°ï¸

# ëª¨ë¸ ë¹Œë“œ & í•™ìŠµí•˜ê¸°

---

ìš°ë¦¬ì˜ ìµœì¢… ëª©í‘œëŠ” resnetìœ¼ë¡œ ëŒë¦¬ëŠ” ê±´ë°, ì¼ë‹¨ í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ [ì´ ë¸”ë¡œê·¸](https://www.analyticsvidhya.com/blog/2020/02/learn-image-classification-cnn-convolutional-neural-networks-3-datasets/)ì—ì„œ sequential APIë¡œ ë§Œë“  cnn ëª¨ë¸ ê·¸ëŒ€ë¡œ ì¨ì£¼ê² ìŒ!

```python
 # building a linear stack of layers with the sequential model
model = Sequential()

# convolutional layer
model.add(Conv2D(50, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu', input_shape=(32, 32, 3)))

# convolutional layer
model.add(Conv2D(75, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))
model.add(MaxPool2D(pool_size=(2,2)))
model.add(Dropout(0.25))

model.add(Conv2D(125, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))
model.add(MaxPool2D(pool_size=(2,2)))
model.add(Dropout(0.25))

# flatten output of conv
model.add(Flatten())

# hidden layer
model.add(Dense(500, activation='relu'))
model.add(Dropout(0.4))
model.add(Dense(250, activation='relu'))
model.add(Dropout(0.3))
# output layer
model.add(Dense(3, activation='softmax'))

# compiling the sequential model
model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')
```

í…ŒìŠ¤íŠ¸ë‹ˆê¹Œ ê°„ë‹¨ì“°í•˜ê²Œ 10epochë§Œ ëŒë ¤ë³´ê¸° ~,~

```python
# training the model for 10 epochs
model.fit(train_images, train_labels, batch_size=64, epochs=10, validation_data=(valid_images, valid_labels))
```

![2020-08-304.56.52.png](/assets/images/posts/2020-09-07/2020-08-304.56.52.png)

ìŒ ê²°ê³¼ê°€ ì•„ì£¼ ë³„ë¡œë‹¤. ê´œì°®ì•„

# ì •í™•ë„ í‰ê°€í•˜ê¸°

---

test_setìœ¼ë¡œ ì •í™•ë„ í‰ê°€í•˜ê¸°~!

```python
test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)

print('\ní…ŒìŠ¤íŠ¸ ì •í™•ë„:', test_acc)
```

![2020-08-304.58.44.png](/assets/images/posts/2020-09-07/2020-08-304.58.44.png)

ì™€ìš° í…ŒìŠ¤íŠ¸ ì •í™•ë„ ì§„ì§œ ë‚œë¦¬ë‚¬ë‹¤. ê´œì°®ë‹¤

# ì˜ˆì¸¡ë§Œë“¤ê¸°

---

```python
prediction = model.predict(test_images)
np.set_printoptions(formatter={'float': lambda x: "{0:0.3f}".format(x)})
```

ê°„ë‹¨í•˜ê²Œë§Œ ë³¼ ê±°ë¼ ì˜ˆì¸¡ ë ˆì´ë¸”ì„ ì•„ë¬´ë ‡ê²Œë‚˜ ì¶œë ¥í•´ë³´ê² ë‹¤!

```python
cnt = 0
for i in prediction:
    pre_ans = i.argmax()
    pre_ans_str = ''
    if pre_ans == 0: pre_ans_str = "drop"
    elif pre_ans == 1: pre_ans_str = "motor"
    elif pre_ans == 2: pre_ans_str = "water"


    if i[0] >= 0.4 : print(f"{test_labels[cnt]} ì´ë¯¸ì§€ëŠ” {pre_ans_str}ë¡œ ì¶”ì •ë©ë‹ˆë‹¤.")
    if i[1] >= 0.4: print(f"{test_labels[cnt]} ì´ë¯¸ì§€ëŠ” {pre_ans_str}ë¡œ ì¶”ì •ë©ë‹ˆë‹¤.")
    if i[2] >= 0.4: print(f"{test_labels[cnt]} ì´ë¯¸ì§€ëŠ” {pre_ans_str}ë¡œ ì¶”ì •ë©ë‹ˆë‹¤.")
    if i[0] < 0.4 and i[1] < 0.4 and i[2] < 0.4 : print(f"{test_labels[i]} ì´ë¯¸ì§€ë¥¼ ì¶”ì •í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print()
    cnt += 1
```

![2020-08-305.04.22.png](/assets/images/posts/2020-09-07/2020-08-305.04.22.png)

ì¢‹ì•„ì“°. ê¸°ë³¸ cnn ëŒì•„ê°€ëŠ”ê±° í™•ì¸í–ˆìœ¼ë‹ˆ ì´ì œ

- resnetìœ¼ë¡œ í•™ìŠµí•˜ê³ 
- ìµœì  ëª¨ë¸ ì €ì¥í•˜ê³ 
- ëª¨ë¸ ë¶ˆëŸ¬ ì™€ì„œ ì˜ˆì¸¡
- ê¸°ê³„í•™ìŠµ ëª¨í˜• ë°°í¬

ì´ë ‡ê²Œ í•´ë³´ê² ë‹¤.

ìš°ë¦¬ëŠ” ì‹¤ì‹œê°„ìœ¼ë¡œ ë“¤ì–´ì˜¤ëŠ” ì†Œë¦¬ ë°ì´í„°ë¥¼ ì…ë ¥ìœ¼ë¡œ í•´ì„œ ì˜ˆì¸¡ ëª¨ë¸ì— ë„£ê³  ì˜ˆì¸¡ê°’ ë°›ê³ , ê·¸ê±¸ ì• í”Œë¦¬ì¼€ì´ì…˜ì— ë„˜ê²¨ì¤˜ì•¼ í•œë‹¤.

ì´ê±¸ sagemakerì—ì„œ í•´ì•¼ í•˜ëŠ”ë°,,, ë¯¸ì¹œ ì•ˆëœë‹¤. ìš¸ê³ ì‹¶ë‹¤. ê·¸ë˜ë„ í•´ì•¼í•˜ë‹ˆ í•´ë³´ê² ë‹¤..^^

ì´ë²ˆ í¬ìŠ¤íŒ… ë ~,~

ë‹¤ìŒ í¬ìŠ¤íŒ… ğŸ‘‰ [ë‚´ ë°ì´í„°ë¡œ ResNet ëŒë ¤ë³´ê¸°](https://www.notion.so/ResNet-d5c9229fc28a46659984c445fb68cfdb)
